"""
Generators for creating documentation files from analyzed project data.
"""

import json
from datetime import datetime
from pathlib import Path
from typing import TYPE_CHECKING

if TYPE_CHECKING:
    from .analyzer import ProjectAnalyzer

from .utils import extract_intent_context, format_project_name


class BaseGenerator:
    """Base class for all generators."""
    
    def __init__(self, analyzer: 'ProjectAnalyzer'):
        """
        Initialize the generator.
        
        Args:
            analyzer: ProjectAnalyzer instance with discovered components
        """
        self.analyzer = analyzer
        self.date = datetime.now().strftime("%Y-%m-%d")
        self.datetime = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    
    def generate(self, *args, **kwargs) -> str:
        """
        Generate the document.
        
        Returns:
            Generated document as string
        """
        raise NotImplementedError("Subclasses must implement generate()")


class SpecGenerator(BaseGenerator):
    """Generator for spec.md files."""
    
    def __init__(self, analyzer: 'ProjectAnalyzer', format_type: str = 'markdown'):
        """
        Initialize the spec generator.
        
        Args:
            analyzer: ProjectAnalyzer instance
            format_type: Output format ('markdown' or 'json')
        """
        super().__init__(analyzer)
        self.format_type = format_type
    
    def generate(self, description: str) -> str:
        """
        Generate specification document.
        
        Args:
            description: Project description for context
            
        Returns:
            Generated spec content
        """
        if self.format_type == 'json':
            return self._generate_json()
        else:
            return self._generate_markdown(description)
    
    def _generate_json(self) -> str:
        """Generate JSON format specification."""
        data = {
            "metadata": {
                "generated": self.date,
                "feature_branch": "main",
                "status": "Active Development"
            },
            "statistics": {
                "endpoints": self.analyzer.endpoint_count,
                "models": self.analyzer.model_count,
                "views": self.analyzer.view_count,
                "services": self.analyzer.service_count,
                "features": self.analyzer.feature_count
            },
            "endpoints": [
                {
                    "method": ep.method,
                    "path": ep.path,
                    "controller": ep.controller,
                    "authenticated": ep.authenticated
                }
                for ep in self.analyzer.endpoints
            ],
            "models": [
                {"name": m.name, "fields": m.fields}
                for m in self.analyzer.models
            ],
            "views": [
                {"name": v.name, "file": v.file_name}
                for v in self.analyzer.views
            ],
            "services": [s.name for s in self.analyzer.services]
        }
        return json.dumps(data, indent=2)
    
    def _generate_markdown(self, description: str) -> str:
        """Generate Markdown format specification."""
        project_info = self.analyzer.get_project_info()
        display_name = format_project_name(project_info["name"])
        
        # Extract intent context from description
        intent_context = extract_intent_context(description)
        
        output = [
            f"# Feature Specification: {display_name}",
            "",
            f"**Feature Branch**: `main`",
            f"**Created**: {self.date}",
            f"**Status**: Active Development",
            f"**Input**: Reverse-engineered from existing codebase",
            "",
            "## Project Overview",
            "",
            project_info["description"],
            "",
            "This specification was automatically generated by reverse-engineering the existing codebase.",
            "It documents the current implementation's capabilities, requirements, and architecture.",
            "",
            "**Note**: This is a living document generated from code analysis. User stories and requirements",
            "below represent the implemented functionality as detected from controllers, models, and services.",
            "",
            "## User Scenarios & Testing *(mandatory)*",
            "",
            f"**Application Purpose**: {description}",
            "",
        ]
        
        # Generate user stories
        story_num = 1
        controllers_seen = set()
        
        for endpoint in self.analyzer.endpoints[:6]:  # Limit to first 6 controllers
            if endpoint.controller in controllers_seen:
                continue
            controllers_seen.add(endpoint.controller)
            
            # Generate story for this controller
            actor, goal, benefit = self._infer_business_outcome(
                endpoint.controller, 
                intent_context
            )
            
            feature_name = endpoint.controller.replace('Controller', '').replace('Api', '')
            priority = "P1" if story_num <= 3 else "P2"
            
            output.extend([
                "",
                f"### User Story {story_num} - {feature_name} (Priority: {priority})",
                "",
                f"As a **{actor}**, I want to **{goal}**",
                f"so that **I can {benefit}**.",
                "",
                "**Why this priority**: Core business value - this capability directly supports the application's primary purpose.",
                "",
                f"**Independent Test**: Can be tested by exercising the available endpoints and verifying that users can achieve the stated goal.",
                "",
                "**Acceptance Scenarios**:",
                "",
                "1. **Given** I have valid data, **When** I make requests, **Then** I receive accurate results",
                "2. **Given** I provide invalid data, **When** I attempt operations, **Then** I receive clear error messages",
                "",
                "---",
            ])
            story_num += 1
        
        # Add UI story if views exist
        if self.analyzer.view_count > 0:
            output.extend([
                "",
                f"### User Story {story_num} - User Interface Interactions (Priority: P1)",
                "",
                "As a **system user**, I want to **interact with a web-based interface**",
                "so that **I can perform operations without needing to use API calls directly**.",
                "",
                f"**Why this priority**: The UI provides the primary user experience with {self.analyzer.view_count} views available.",
                "",
                "**Independent Test**: Can be fully tested by navigating through available views and verifying all interactive elements function correctly.",
                "",
                "**Acceptance Scenarios**:",
                "",
                "1. **Given** I access the application, **When** I navigate between views, **Then** the interface responds smoothly",
                "2. **Given** I interact with forms, **When** I submit data, **Then** it is processed correctly",
                "3. **Given** I view data displays, **When** information is loaded, **Then** it is presented clearly and accurately",
                "4. **Given** errors occur, **When** I receive feedback, **Then** messages are helpful and actionable",
                "",
                "---",
            ])
        
        # Add edge cases and requirements
        output.extend([
            "",
            "### Edge Cases",
            "",
            "- What happens when **invalid data is submitted** to API endpoints?",
            "- How does the system handle **concurrent modifications** to the same entity?",
            "- What occurs when **required authentication** is missing or expired?",
            "- How does the system respond to **malformed JSON** in requests?",
            "- What happens when **database connections fail** during operations?",
            "",
            "## Requirements *(mandatory)*",
            "",
            "### Functional Requirements",
            "",
        ])
        
        # Generate functional requirements
        req_counter = 1
        
        # Check for authentication
        if any(ep.authenticated for ep in self.analyzer.endpoints):
            output.append(f"- **FR-{req_counter:03d}**: System MUST provide authentication and authorization for protected endpoints")
            req_counter += 1
        
        # Check for HTTP methods
        methods = set(ep.method for ep in self.analyzer.endpoints)
        if "GET" in methods:
            output.append(f"- **FR-{req_counter:03d}**: System MUST support retrieval of data via GET endpoints")
            req_counter += 1
        if "POST" in methods:
            output.append(f"- **FR-{req_counter:03d}**: System MUST support creation of new entities via POST endpoints")
            req_counter += 1
        if "PUT" in methods or "PATCH" in methods:
            output.append(f"- **FR-{req_counter:03d}**: System MUST support updates to existing entities via PUT/PATCH endpoints")
            req_counter += 1
        if "DELETE" in methods:
            output.append(f"- **FR-{req_counter:03d}**: System MUST support deletion of entities via DELETE endpoints")
            req_counter += 1
        
        output.extend([
            f"- **FR-{req_counter:03d}**: System MUST validate all input data for correctness and completeness",
        ])
        req_counter += 1
        output.extend([
            f"- **FR-{req_counter:03d}**: System MUST return appropriate HTTP status codes for all operations",
        ])
        req_counter += 1
        output.extend([
            f"- **FR-{req_counter:03d}**: System MUST handle errors gracefully with meaningful error messages",
        ])
        req_counter += 1
        
        if self.analyzer.model_count > 0:
            output.append(f"- **FR-{req_counter:03d}**: System MUST persist data using {self.analyzer.model_count} defined data models")
        
        # Key entities
        output.extend([
            "",
            "### Key Entities",
            "",
            f"**Discovered Models** ({self.analyzer.model_count} total):",
            "",
        ])
        
        for model in self.analyzer.models:
            output.append(f"- **{model.name}**: {model.fields} fields")
        
        # Success criteria
        output.extend([
            "",
            "## Success Criteria *(mandatory)*",
            "",
            "### Measurable Outcomes",
            "",
            "- **SC-001**: API endpoints respond within acceptable time limits (< 2 seconds for 95% of requests)",
            "- **SC-002**: System successfully handles concurrent requests without data corruption",
            "- **SC-003**: All CRUD operations complete successfully with proper validation",
            "- **SC-004**: Error responses include meaningful messages and appropriate HTTP status codes",
            "- **SC-005**: Data persistence maintains integrity across all operations",
            "- **SC-006**: Authentication and authorization function correctly for protected resources",
            f"- **SC-007**: System scales to handle expected user load ({self.analyzer.endpoint_count} endpoints, {self.analyzer.model_count} models)",
            "- **SC-008**: All functional requirements are testable and verified",
            "",
            "## Technical Implementation Details",
            "",
            "### API Endpoints Discovered",
            "",
            f"Total endpoints: {self.analyzer.endpoint_count}",
            "",
        ])
        
        # Group endpoints by controller
        current_controller = ""
        for endpoint in self.analyzer.endpoints:
            if endpoint.controller != current_controller:
                if current_controller:
                    output.append("")
                output.append(f"**{endpoint.controller} Controller**:")
                output.append("")
                current_controller = endpoint.controller
            
            output.append(f"- `{endpoint.method} {endpoint.path}` {endpoint}")
        
        # UI Views
        output.extend([
            "",
            "### UI Views Discovered",
            "",
            f"Total views: {self.analyzer.view_count}",
            "",
        ])
        
        for view in self.analyzer.views:
            output.append(f"- **{view.name}**: `{view.file_name}`")
        
        # Backend services
        output.extend([
            "",
            "### Backend Services Discovered",
            "",
            f"Total services: {self.analyzer.service_count}",
            "",
        ])
        
        for service in self.analyzer.services:
            output.append(f"- {service.name}")
        
        # Technology stack
        output.extend([
            "",
            "### Technology Stack",
            "",
        ])
        
        if project_info["language"] != "NEEDS CLARIFICATION":
            output.append(f"- **Language/Runtime**: {project_info['language']}")
        
        if project_info["dependencies"] != "NEEDS CLARIFICATION":
            formatted_deps = project_info["dependencies"].replace(", ", " + ")
            output.append(f"- **Frameworks**: {formatted_deps}")
        
        if project_info["storage"] != "N/A":
            formatted_storage = project_info["storage"].replace(", ", " + ")
            output.append(f"- **Data Storage**: {formatted_storage}")
        
        if project_info["testing"] != "NEEDS CLARIFICATION":
            formatted_testing = project_info["testing"].replace(", ", " + ")
            output.append(f"- **Testing**: {formatted_testing}")
        
        # Check for build tools
        if list(self.analyzer.repo_root.rglob("pom.xml")):
            output.append("- **Build Tool**: Maven")
        elif list(self.analyzer.repo_root.rglob("build.gradle")):
            output.append("- **Build Tool**: Gradle")
        elif list(self.analyzer.repo_root.rglob("package.json")):
            output.append("- **Build Tool**: npm/yarn/pnpm")
        
        # Footer
        output.extend([
            "",
            "---",
            "",
            f"**Generated**: {self.date} by reverse-engineer",
            f"**Analysis**: {self.analyzer.endpoint_count} endpoints, {self.analyzer.model_count} models, {self.analyzer.view_count} views, {self.analyzer.service_count} services",
        ])
        
        return "\n".join(output)
    
    def _infer_business_outcome(self, controller: str, intent_context: dict) -> tuple:
        """Infer actor, goal, and benefit for a controller."""
        # Simple inference based on controller name
        controller_lower = controller.lower()
        
        # Infer actor
        if "auth" in controller_lower or "login" in controller_lower:
            actor = "system user"
        elif "admin" in controller_lower:
            actor = "administrator"
        else:
            actor = "user"
        
        # Infer goal and benefit
        entity = controller.replace("Controller", "").replace("Api", "")
        
        # Use intent verbs if available
        if intent_context.get("verbs"):
            verb = intent_context["verbs"][0]
            goal = f"{verb} {entity} data"
            benefit = f"support {verb} operations effectively"
        else:
            goal = f"manage {entity} data"
            benefit = f"maintain accurate {entity} information"
        
        return actor, goal, benefit


class PlanGenerator(BaseGenerator):
    """Generator for plan.md files."""
    
    def generate(self) -> str:
        """Generate implementation plan document."""
        project_info = self.analyzer.get_project_info()
        display_name = format_project_name(project_info["name"])
        project_type = project_info["type"]
        project_name = self.analyzer.repo_root.name
        
        output = [
            f"# Implementation Plan: {display_name}",
            "",
            f"**Branch**: `{project_name}` | **Date**: {self.date} | **Spec**: [spec.md](./spec.md)",
            "**Input**: Reverse-engineered specification from existing codebase",
            "",
            f"**Note**: This plan documents the current implementation state of the {display_name}",
            "application, generated through reverse-engineering analysis. Unlike typical plans that",
            "guide future development, this serves as architectural documentation of what exists.",
            "",
            "---",
            "",
            "## Summary",
            "",
            project_info["description"],
            "",
            "**Primary Capabilities**:",
            f"- RESTful API with {self.analyzer.endpoint_count} endpoints",
            f"- Data management with {self.analyzer.model_count} models",
        ]
        
        if self.analyzer.view_count > 0:
            output.append(f"- User interface with {self.analyzer.view_count} views")
        
        if self.analyzer.service_count > 0:
            output.append(f"- Business logic layer with {self.analyzer.service_count} services")
        
        output.extend([
            "",
            "**Technical Approach**:",
        ])
        
        if project_info["language"] != "NEEDS CLARIFICATION":
            output.append(f"- {project_info['language']} runtime")
        
        if project_info["dependencies"] != "NEEDS CLARIFICATION":
            for dep in project_info["dependencies"].split(", "):
                output.append(f"- {dep} framework")
        
        if project_info["storage"] != "N/A":
            output.append(f"- {project_info['storage']} for data persistence")
        
        # Add more sections
        output.extend([
            "",
            "---",
            "",
            "## Technical Context",
            "",
            f"**Language/Version**: {project_info['language']}",
            f"**Primary Dependencies**: {project_info['dependencies']}",
            f"**Storage**: {project_info['storage']}",
            f"**Testing**: {project_info['testing']}",
            "**Target Platform**: Docker containers (Linux), Web browsers (ES2015+)",
            f"**Project Type**: {project_type}",
            "**Performance Goals**: <500ms API response time, efficient data processing, optimal resource utilization",
            "**Constraints**: Scalable architecture, maintainable codebase, robust error handling",
            f"**Scale/Scope**: {self.analyzer.endpoint_count} API endpoints, {self.analyzer.model_count} data models, {self.analyzer.view_count} UI views",
            "",
            "---",
            "",
            "## Project Structure",
            "",
            "### Documentation (this feature)",
            "",
            "```",
            "specs/001-reverse/",
            "├── spec.md              # Reverse-engineered specification",
            "└── plan.md              # This file (implementation plan)",
            "```",
            "",
            "---",
            "",
            "## Phase 1: Design & Contracts",
            "",
            "**Status**: ✅ COMPLETE (Existing Implementation)",
            "",
            "The following design artifacts exist in the current codebase:",
            "",
            "### API Endpoints",
            "",
            f"**API Endpoints** ({self.analyzer.endpoint_count} endpoints):",
            "",
        ])
        
        # Group endpoints by controller
        current_controller = ""
        for endpoint in self.analyzer.endpoints:
            if endpoint.controller != current_controller:
                output.append("")
                output.append(f"**{endpoint.controller}Controller**:")
                current_controller = endpoint.controller
            output.append(f"- {endpoint}")
        
        output.extend([
            "",
            "### Data Models",
            "",
            f"**Entities** ({self.analyzer.model_count} models):",
            "",
        ])
        
        for model in self.analyzer.models:
            output.append(f"- **{model.name}** - {model.fields} fields")
        
        if self.analyzer.view_count > 0:
            output.extend([
                "",
                "### Views & Components",
                "",
                f"**UI Views** ({self.analyzer.view_count} views):",
                "",
            ])
            
            for view in self.analyzer.views:
                output.append(f"- **{view.name}** - `{view.file_name}`")
        
        output.extend([
            "",
            "---",
            "",
            "## Key Decisions & Rationale",
            "",
            "### Technology Choices",
            "",
        ])
        
        # Add technology rationale based on detected stack
        if "Spring Boot" in project_info["dependencies"]:
            output.extend([
                "**Backend: Spring Boot**",
                "- Rationale: Industry-standard framework with excellent security, testing, and documentation",
                "- Alternatives considered: Quarkus (less mature), Node.js (team expertise with Java)",
                "",
            ])
        
        if "Vue.js" in project_info["dependencies"]:
            output.extend([
                "**Frontend: Vue.js 3**",
                "- Rationale: Progressive framework with excellent developer experience and Composition API",
                "- Alternatives considered: React (more complex state management), Angular (heavier)",
                "",
            ])
        
        if "MongoDB" in project_info["storage"]:
            output.extend([
                "**Database: MongoDB**",
                "- Rationale: Flexible schema for evolving data requirements, excellent JSON integration",
                "- Alternatives considered: PostgreSQL (less flexible schema), MySQL (dated)",
                "",
            ])
        
        output.extend([
            "---",
            "",
            "## Next Steps",
            "",
            "Since this is a reverse-engineered plan, next steps depend on your goal:",
            "",
            "### For Documentation",
            "- ✅ spec.md and plan.md are now generated",
            "- Consider adding architecture diagrams",
            "- Document deployment procedures",
            "- Create API documentation (Swagger/OpenAPI)",
            "",
            "### For New Features",
            "1. Create new feature specification",
            "2. Generate implementation plan",
            "3. Break down into tasks",
            "4. Implement and test",
            "",
            "---",
            "",
            "## Maintenance Notes",
            "",
            f"**Last Analysis**: {self.datetime}",
            "**Script**: reverse-engineer",
            f"**Analysis Stats**: {self.analyzer.endpoint_count} endpoints, {self.analyzer.model_count} models, {self.analyzer.view_count} views, {self.analyzer.service_count} services",
            "",
            "To regenerate this plan:",
            "```bash",
            "reverse-engineer --plan",
            "```",
        ])
        
        return "\n".join(output)


class DataModelGenerator(BaseGenerator):
    """Generator for data-model.md files."""
    
    def generate(self) -> str:
        """Generate data model documentation."""
        project_info = self.analyzer.get_project_info()
        display_name = format_project_name(project_info["name"])
        
        output = [
            f"# Data Models: {display_name}",
            "",
            f"**Generated**: {self.date}",
            "**Source**: Reverse-engineered from project models",
            f"**Total Models**: {self.analyzer.model_count}",
            "",
            f"This document provides comprehensive documentation for all data models in the {display_name} application.",
            "",
            "---",
            "",
            "## Overview",
            "",
            f"The {display_name} uses {self.analyzer.model_count} data models to represent the domain:",
            "",
        ]
        
        for model in self.analyzer.models:
            output.append(f"- **{model.name}** - {model.fields} fields")
        
        output.extend([
            "",
            "---",
            "",
            "## Model Descriptions",
            "",
        ])
        
        # Generate detailed sections for each model
        for model in self.analyzer.models:
            output.extend([
                "",
                f"### {model.name}",
                "",
                f"**Location**: `{model.file_path.relative_to(self.analyzer.repo_root) if model.file_path else 'Unknown'}`",
                f"**Fields**: {model.fields}",
                "",
            ])
            
            if model.file_path and model.file_path.exists():
                try:
                    content = model.file_path.read_text()
                    
                    # Extract class-level JavaDoc
                    import re
                    javadoc_match = re.search(r'/\*\*(.*?)\*/', content, re.DOTALL)
                    if javadoc_match:
                        javadoc = javadoc_match.group(1)
                        # Clean up JavaDoc
                        javadoc_lines = [
                            line.strip().lstrip('*').strip()
                            for line in javadoc.split('\n')
                            if line.strip() and not line.strip().startswith('@')
                        ]
                        if javadoc_lines:
                            output.append("**Description**:")
                            output.extend(javadoc_lines[:5])  # Limit to 5 lines
                            output.append("")
                    
                    # Extract field information
                    output.append("**Fields**:")
                    output.append("")
                    
                    field_pattern = r'private\s+(\S+)\s+(\S+);'
                    for match in re.finditer(field_pattern, content):
                        field_type = match.group(1)
                        field_name = match.group(2)
                        output.append(f"- `{field_name}` (`{field_type}`)")
                    
                    output.append("")
                    
                    # Check for MongoDB document annotation
                    if '@Document' in content:
                        collection_match = re.search(r'collection\s*=\s*"([^"]*)"', content)
                        if collection_match:
                            output.append(f"**MongoDB Collection**: `{collection_match.group(1)}`")
                            output.append("")
                    
                    # Check for relationships
                    if '@DBRef' in content:
                        output.append("**Relationships**: Contains database references to other documents")
                        output.append("")
                
                except Exception:
                    output.append("*Model file not accessible for detailed analysis*")
                    output.append("")
            else:
                output.append("*Model file not found or not accessible for detailed analysis*")
                output.append("")
            
            output.append("---")
        
        output.extend([
            "",
            "## Model Relationships",
            "",
            "The model relationships are determined by examining `@DBRef`, `@OneToMany`, `@ManyToOne`,",
            "and other relationship annotations in the source code. Refer to the individual model",
            "documentation above for specific relationship details.",
            "",
            "## Usage Patterns",
            "",
            "The usage patterns for these models are determined by the service layer and controller",
            "implementations. Common patterns include:",
            "",
            "1. **CRUD Operations**: Create, Read, Update, Delete operations for entity management",
            "2. **Data Validation**: JSR-303 validation annotations ensure data integrity",
            "3. **Persistence**: JPA/MongoDB annotations handle database mapping",
            "4. **Business Logic**: Service classes orchestrate model interactions",
            "",
            "---",
            "",
            "**Note**: This documentation was auto-generated by analyzing the Java model files. For the most up-to-date field information, refer to the source code.",
        ])
        
        return "\n".join(output)


class ApiContractGenerator(BaseGenerator):
    """Generator for OpenAPI 3.0 specification (api-spec.json)."""
    
    def generate(self) -> str:
        """Generate OpenAPI specification."""
        project_info = self.analyzer.get_project_info()
        project_name = project_info["name"]
        display_name = format_project_name(project_name)
        
        api_title = f"{display_name} API"
        api_description = project_info["description"]
        api_version = "1.0.0"
        
        # Try to detect version from pom.xml
        for pom_file in self.analyzer.repo_root.rglob("pom.xml"):
            try:
                import re
                content = pom_file.read_text()
                version_match = re.search(r'<version>([^<]+)</version>', content)
                if version_match:
                    api_version = version_match.group(1)
                    break
            except Exception:
                pass
        
        # Build OpenAPI spec
        spec = {
            "openapi": "3.0.3",
            "info": {
                "title": api_title,
                "description": api_description,
                "version": api_version,
                "contact": {
                    "name": "API Support"
                },
                "license": {
                    "name": "MIT"
                }
            },
            "servers": [
                {
                    "url": "http://localhost:8080",
                    "description": "Development server"
                }
            ],
            "security": [
                {
                    "bearerAuth": []
                }
            ],
            "components": {
                "securitySchemes": {
                    "bearerAuth": {
                        "type": "http",
                        "scheme": "bearer",
                        "bearerFormat": "JWT",
                        "description": "JWT token obtained from authentication endpoint"
                    }
                },
                "schemas": self._generate_schemas()
            },
            "paths": self._generate_paths(),
            "tags": self._generate_tags()
        }
        
        return json.dumps(spec, indent=2)
    
    def _generate_schemas(self) -> dict:
        """Generate component schemas for models."""
        schemas = {}
        
        # Add model schemas
        for model in self.analyzer.models:
            schemas[model.name] = {
                "type": "object",
                "description": f"Data model for {model.name}",
                "properties": {
                    "id": {
                        "type": "string",
                        "description": "Unique identifier"
                    }
                }
            }
            
            # Try to extract actual fields if file exists
            if model.file_path and model.file_path.exists():
                try:
                    import re
                    content = model.file_path.read_text()
                    field_pattern = r'private\s+(\S+)\s+(\S+);'
                    
                    properties = {}
                    for match in re.finditer(field_pattern, content):
                        field_type = match.group(1)
                        field_name = match.group(2)
                        
                        # Map Java types to OpenAPI types
                        openapi_type = self._map_type(field_type)
                        properties[field_name] = {"type": openapi_type}
                    
                    if properties:
                        schemas[model.name]["properties"] = properties
                
                except Exception:
                    pass
        
        # Add common schemas
        schemas["Error"] = {
            "type": "object",
            "properties": {
                "error": {
                    "type": "string",
                    "description": "Error message"
                },
                "status": {
                    "type": "integer",
                    "description": "HTTP status code"
                }
            }
        }
        
        schemas["AuthResponse"] = {
            "type": "object",
            "properties": {
                "token": {
                    "type": "string",
                    "description": "JWT authentication token"
                },
                "expiresIn": {
                    "type": "integer",
                    "description": "Token expiration time in seconds"
                }
            }
        }
        
        return schemas
    
    def _map_type(self, java_type: str) -> str:
        """Map Java type to OpenAPI type."""
        type_map = {
            "String": "string",
            "Integer": "integer",
            "int": "integer",
            "Long": "integer",
            "long": "integer",
            "Double": "number",
            "double": "number",
            "Float": "number",
            "float": "number",
            "Boolean": "boolean",
            "boolean": "boolean",
            "Date": "string",
            "LocalDate": "string",
            "LocalDateTime": "string",
            "Instant": "string",
        }
        
        if java_type.startswith("List") or java_type.startswith("ArrayList"):
            return "array"
        
        return type_map.get(java_type, "object")
    
    def _generate_paths(self) -> dict:
        """Generate API paths from endpoints."""
        paths = {}
        
        for endpoint in self.analyzer.endpoints:
            path = endpoint.path or "/"
            method = endpoint.method.lower()
            
            if path not in paths:
                paths[path] = {}
            
            operation_id = f"{endpoint.controller}{endpoint.method.capitalize()}"
            summary = f"{endpoint.method} {endpoint.controller}"
            
            operation = {
                "operationId": operation_id,
                "summary": summary,
                "description": f"Endpoint for {endpoint.controller}",
                "tags": [endpoint.controller]
            }
            
            if endpoint.authenticated:
                operation["security"] = [{"bearerAuth": []}]
            
            # Add responses
            operation["responses"] = self._generate_responses(endpoint.method)
            
            # Add request body for POST/PUT/PATCH
            if endpoint.method in ["POST", "PUT", "PATCH"]:
                operation["requestBody"] = {
                    "required": True,
                    "content": {
                        "application/json": {
                            "schema": {
                                "$ref": "#/components/schemas/object"
                            }
                        }
                    }
                }
            
            paths[path][method] = operation
        
        return paths
    
    def _generate_responses(self, method: str) -> dict:
        """Generate response definitions based on HTTP method."""
        if method == "GET":
            return {
                "200": {
                    "description": "Successful response",
                    "content": {
                        "application/json": {
                            "schema": {
                                "type": "object"
                            }
                        }
                    }
                },
                "404": {
                    "description": "Resource not found",
                    "content": {
                        "application/json": {
                            "schema": {
                                "$ref": "#/components/schemas/Error"
                            }
                        }
                    }
                }
            }
        elif method == "POST":
            return {
                "201": {
                    "description": "Resource created successfully",
                    "content": {
                        "application/json": {
                            "schema": {
                                "type": "object"
                            }
                        }
                    }
                },
                "400": {
                    "description": "Invalid request data",
                    "content": {
                        "application/json": {
                            "schema": {
                                "$ref": "#/components/schemas/Error"
                            }
                        }
                    }
                }
            }
        elif method in ["PUT", "PATCH"]:
            return {
                "200": {
                    "description": "Resource updated successfully",
                    "content": {
                        "application/json": {
                            "schema": {
                                "type": "object"
                            }
                        }
                    }
                },
                "404": {
                    "description": "Resource not found",
                    "content": {
                        "application/json": {
                            "schema": {
                                "$ref": "#/components/schemas/Error"
                            }
                        }
                    }
                }
            }
        elif method == "DELETE":
            return {
                "204": {
                    "description": "Resource deleted successfully"
                },
                "404": {
                    "description": "Resource not found",
                    "content": {
                        "application/json": {
                            "schema": {
                                "$ref": "#/components/schemas/Error"
                            }
                        }
                    }
                }
            }
        else:
            return {
                "200": {
                    "description": "Successful response"
                }
            }
    
    def _generate_tags(self) -> list:
        """Generate tags for controllers."""
        controllers = set(ep.controller for ep in self.analyzer.endpoints)
        
        return [
            {
                "name": controller,
                "description": f"Operations for {controller} management"
            }
            for controller in sorted(controllers)
        ]
